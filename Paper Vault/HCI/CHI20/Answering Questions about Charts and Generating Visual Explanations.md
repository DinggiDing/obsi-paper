---
시작일: 2024-10-15
진행상태: false
tags:
  - HCI
  - Visualization
  - Explainable-AI
sticker: lucide//settings-2
Author: Dae hyun Kim
---
- They developed an automatic chart question answering pipeline that generates visual explanations describing how the answer was obtained

1. Extracts the data and visual encodings from **an input Vega-Lite chart**
2. Given a natural language question about the chart, it transforms references to visual attributes into **references to the data**
3. It applies **a machine learning algorithm** to answer the transformed question
4. It uses a template-based[^1] approach to explain in natural language **how the answer is determined from the chart's visual features**
[^1]: 미리 정의된 문장 구조나 문장형식을 활용


# 1 Introduction
---
- Answering complex questions that require combining multiple visual attributes can be challenging
- They approach builds on Sempre, a question-answering system for relational data tables that focuses on answering compositional, non-visual questions
- *According to formative study,* they find that people frequestly ask compositional questions(70%)
	- Compositional question - comparing values and calculating sums... 
- the visual encoding structure of a chart is very useful for automatic chart question answering

# 3 Formative Study
---
- Lookup questions were often visual, while compositional question were more likely to be non-visual
- People frequestly ask compositional questions, and visual explanations were perceived as clearer

# 4 Method
---
### Stage 1 : Extract data table and encodings
- They Convert an input data into Vega-Lite specification and then extract encodings as well as the transformed data. 
- **Extract Encodings** : Extract encodings by looking for "encoding" keyword
- **Extract Data** : To get a flat relational table(such as single data tuple), they run the Vega-Lite interpreter and apply all data transformations in the chart specification
- **Unfold Data Table** : Table question answering systems like sempre are trained using human readable tables(unfolded format)

### Stage 2 : Visual to Non-Visual Question Conversation
- Why? - 컴퓨터가 단순히 시각적 특징만 이해하기 어려움, Sempre 시스템은 비시각적 데이터에 최적화됨, 복복잡한 연산(비교, 덧셈) 가능해짐
- The system transforms questions referring to visual attributes into non-visual question(data-centric)
Ex) "*Which religion has the longest orange component?*" →  "*Which religion has the most Percentage of Common Response data?*"
- **1. Mark detection** : Detect all words referring to graphical marks in the chart. 
	- ex) component, portion and segment are included in the list for bar marks manually
- **2. Dependency parsing** : It helps identify relationships between words like "longest" and "bar" in question
- **3. Visual attribute detection** : Identify all the visual attribute words(such as color, length) in the list of descriptive words
- **4. Visual operation detection** : Interpret "longest" words as the visual operation(argmax)
- **5. Apply encodings** : Replace visual attributes with correspoding data fields ("color" →  "response: Common")
- **6. Natural language conversion**

### Stage 3 : Explanation Generation
- The lambda expression generated by Sempre is converted into a natural lnaguage explanation using templates
- **1. Natural language conversion** : our pipeline applies the argmax, type, lookup, and row rules to convert the input lambda expression to “‘Religion’ of data with the greatest ‘Common’ of ‘Religion’.”
- **2. Implicit field recovery** : Sometimes, a field name becomes implicit during the table unfolding in Stage 1
- **3. Redundancy cleanup** : our pipelines removes any redundant information using a series of regex rules
- **4. Sentence completion** : Generate a non-visual explanation by adding the pronoun 'I' and a verb
- **5. Encoding application** : Apply the visual encodings obtained from Stage 1

# 5 Result
---
- Comparing it with the baseline Sempre
- 51% Accuracy (Sempre : 39%)
- The pipeline excelled in visual questions with a 53% accuracy rate.

# 6 User Study
---
- to evaluate trust, transparency, usefulness
- 4 different conditions(`No explanation`, `Human explanation`, `Non-visual explanation`, `Visual explanation` )
	- H1 : visual explanation 👍 >  no explanation
		- visual explanations generated by our pipeline significantly increased the `transparency` of the pipeline compared to the no-explanation condition
	- H2 : Visual explanation 👍 >= Human explanation
		- our pipeline significantly more `transparent` than the human-generated explanations
	- H3 : Visual explanation 👍 > Non-visual explanation
		- none of the improvements are significant
- Participants were given questions about different charts ( using [[7-point likert scale]])

> In sum, we find the visual explanations generated by our system are significantly more `transparent` than human-generated explanations and are comparable in `usefulness` and `trust`.


# 7 Limitations
---
- Handling compositional quesion is difficult
- Limitations of the Sempre system
- Lack of flexibility in Template-baed explanations


##### vs Data Formulator ([[Data Formulator - AI-powered Concept-driven Visualization Authoring]])
- 이 논문은 차트에 대한 질문과 답변 정확도를 개선하는데 초점을 둠, Data Formulator는 데이터 변환과 차트 설계, 데이터 시각화 생성 및 편집에 초점
- 두 논문 다 AI를 활용하여 데이터와 차트에 대한 이해를 도움.