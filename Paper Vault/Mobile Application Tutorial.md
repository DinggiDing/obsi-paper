
- 앱 튜토리얼 자동화
    - 노인 + LLM + literacy
    - 다양한 material로 (data만 있으면 가능)
    - 주요
        - 적응형 학습 시스템
            - 개인의 학습속도와 이해도 반영하여 튜토리얼 내용 조정
        - 멀티모달 학습
        - 인터랙티브 튜토리얼
            - 피드백
        - 사회적 지원
            - 여러 사람들(친구, 가족, 커뮤니티)의 지원
        - 게임

- EasyAsk (IMWUT24)
	- 노인
	- 음성과 터치 입력을 통해 질문을 자연스럽게하고 필요한 튜토리얼을 검색할 수 있도록 설계됨
	- 음성텍스트 + 사용자가 특정 UI 터치할 때 해당 정보 캡처하여 의도 파악
	- LLM(GPT-4) 통해 질문 이해하기 쉽게 재구성
	- 14앱의 578개 DB 구축하여 그 중에서 튜토리얼 검색
		- **컨텍스트 정보 보완**
		    - 사용자가 앱을 사용하는 상황을 파악하여 추가적인 정보 자동 보완. 음성 인식 소프트웨어(iFlytek API)를 통해 음성 입력을 텍스트로 변환하고, Android 접근성 서비스를 활용해 사용자가 터치한 인터페이스 요소 등의 컨텍스트 정보 수집. 이러한 방식으로 사용자의 질문을 보다 명확하게 해석.
		- **질문 형식화**
		    - 질문의 불완전성과 중복된 정보 문제를 해결하기 위해, EasyAsk는 GPT-4와 같은 언어 모델을 사용하여 사용자의 질문을 정돈하고 최적화. 사용자가 자주 사용하는 특정 앱의 용어와 고령층의 질문 패턴을 반영한 프롬프트를 언어 모델에 입력하여 질문을 간결하고 정확하게 변환합​.
		- **튜토리얼 검색**
		    - 연구팀은 고령층 사용자가 자주 사용하는 앱에 대한 578개의 튜토리얼로 데이터베이스를 구성하고, 각 튜토리얼은 JSON 파일로 기록된 단계별 상호작용 지침을 포함. LangChain과 FAISS를 이용해 튜토리얼 지식을 검색 가능하게 하고, 사용자의 최종 질문을 바탕으로 GPT-4가 최적의 튜토리얼을 추천하도록 설정함​.
		- **시스템 구현**
			    - Android용 앱으로 개발되었으며, Android 13까지 지원하며 루트 권한이 필요 X. 튜토리얼과 사용자 로그는 서버에 안전하게 저장됩니다​.
- EverTutor (CHI14)
	- 스마트폰에서 사용자가 데모를 수행하면 그 데이터를 기반으로 자동으로 상호작용형 튜토리얼을 생성하는 시스템
	- 제스처 인식, 스크린샷 추출
	- 튜토리얼 생성과정
		- 사용자가 특정 작업 수행 →  EverTutor가 행동 기록 캡처(로그) →  튜토리얼 생성 
	- 튜토리얼 보면서 EverTutor가 정확히 수행되는지 확인
- HelpCall(CHI24)
	- 노인, 데스크탑 (마우스 등 활용)), 비디오 컨퍼런싱 기반 원격 지원 도구
	- Tooltip, List 
	- 실시간 단계별 지침(ASD)은 고령자들이 기술 과제를 수행할 때 지침을 쉽게 따를 수 있도록 도와주며, 특히 툴팁 방식이 고령자들에게 더 간편하게 사용될 수 있는 것으로 평가됨.
- Interaction Proxies for Runtime Repair and Enhancement of Mobile Application Accessibility (CHI17)
	- 모바일 앱의 원래 인터페이스와 사용자가 인지하고 조작하는 인터페이스 사이에 프록시를 삽입하여, 제3자가 앱의 소스 코드나 플랫폼 자체를 수정하지 않고 접근성을 개선할 수 있도록 함.
	- 플로팅 윈도우로 접근성 정보 추가
	- 접근성 API를 통해 버튼 클릭, 텍스트 입력 등을 프로그래밍적으로 수행
- iTutor (UIST23)
	- 노인 사용자에게 단계별 지침을 제공하는 생성형 튜토리얼 시스템
	- 메타데이터 수집 - UI 페이지 이미지를 텍스트 요소로 변환 →  LLM 입력 데이터에 사용
	- 프롬프트 기법 이용하여 지침 생성 > VUI(음성 사용자 인터페이스)로 지침 제공, 시각적 강조 효과를 통해 UI 요소의 위치와 조작방법 전달.
	- 동적으로 튜토리얼 업데이트 가능
- Senior Technology Learning Preferences Model for Mobile Technology
	- 노년층의 다양한 학습 선호도(매뉴얼, 검색엔진, 동영상)와 지원 유형(가족, 친구, 동료)의 영향 평가
	- "Mobile Device Proficiency Questionnaire (MDPQ-14)"를 통해 평가
	- 노년층과 젊은 지원자 간의 상호작용을 통해 학습 및 지원의 선호도를 분석
	- 가까운 사람이 있거나 쉽게 도움을 받을 수 있다고 느낄 때 노인들은 더 자주 새로운 기능을 탐색하려는 경향을 보입니다
	- 자신감이 있는 경우 자기 탐색을 선호하며, 그렇지 않은 경우 사회적 학습을 더 선호합니다.
- Reducing the Search Space on demand helps Older Adults find Mobile UI Features quickly, on par with Younger Adults(CHI 24)
	- 연구진은 기능 검색 공간을 줄여서 선택 가능한 기능의 수를 제한하면 고령층도 젊은 사용자와 비슷한 속도로 UI 기능을 찾을 수 있을 것이라고 가정
	- 사용자 쿼리(음성인식)로 탐색 공간 찾기
	- 4가지 시각적 강조 기법(단순 하이라이트, **문맥 포함 하이라이트**, 줌, **가중 줌**) 테스트
- Synapse(IMWUT 22)
	- Trial-and-Error mode + voice mode    →  노년층에서 유용
	- 예를 들어, 사용자가 잘못된 위치를 클릭한 경우 음성 안내와 함께 이전 단계로 돌아가는 방법을 제공하여 오류를 무서워하지 않고 자유롭게 학습할 수 있는 환경을 조성​. 
	- **시도-오류 모드**에서는 사용자가 자유롭게 앱을 탐색하고, 잘못된 클릭이 발생하면 경고를 제공하여 사용자가 실수를 통해 학습할 수 있도록 돕습니다. 또한, 사용자가 “찾을 수 없습니다”라고 말하면 음성으로 도움을 받을 수 있는 기능도 포함
	- 튜토리얼 생성 : 제스처, 터치 + 음성 녹음
- Video2Action(UIST23)
	- 액션 장면 생성 - 비디오를 분석하여 Tap, Scroll, Backward 같은 UI 전환 패턴 파악
	- 액션 위치 예측 - 딥러닝 모델을 사용하여 Tap 위치 예측